{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/139\n",
      "Participant: 2/139\n",
      "Participant: 3/139\n",
      "Participant: 4/139\n",
      "Participant: 5/139\n",
      "Participant: 6/139\n",
      "Participant: 7/139\n",
      "Participant: 8/139\n",
      "Participant: 9/139\n",
      "Participant: 10/139\n",
      "Participant: 11/139\n",
      "Participant: 12/139\n",
      "Participant: 13/139\n",
      "Participant: 14/139\n",
      "Participant: 15/139\n",
      "Participant: 16/139\n",
      "Participant: 17/139\n",
      "Participant: 18/139\n",
      "Participant: 19/139\n",
      "Participant: 20/139\n",
      "Participant: 21/139\n",
      "Participant: 22/139\n",
      "Participant: 23/139\n",
      "Participant: 24/139\n",
      "Participant: 25/139\n",
      "Participant: 26/139\n",
      "Participant: 27/139\n",
      "Participant: 28/139\n",
      "Participant: 29/139\n",
      "Participant: 30/139\n",
      "Participant: 31/139\n",
      "Participant: 32/139\n",
      "Participant: 33/139\n",
      "Participant: 34/139\n",
      "Participant: 35/139\n",
      "Participant: 36/139\n",
      "Participant: 37/139\n",
      "Participant: 38/139\n",
      "Participant: 39/139\n",
      "Participant: 40/139\n",
      "Participant: 41/139\n",
      "Participant: 42/139\n",
      "Participant: 43/139\n",
      "Participant: 44/139\n",
      "Participant: 45/139\n",
      "Participant: 46/139\n",
      "Participant: 47/139\n",
      "Participant: 48/139\n",
      "Participant: 49/139\n",
      "Participant: 50/139\n",
      "Participant: 51/139\n",
      "Participant: 52/139\n",
      "Participant: 53/139\n",
      "Participant: 54/139\n",
      "Participant: 55/139\n",
      "Participant: 56/139\n",
      "Participant: 57/139\n",
      "Participant: 58/139\n",
      "Participant: 59/139\n",
      "Participant: 60/139\n",
      "Participant: 61/139\n",
      "Participant: 62/139\n",
      "Participant: 63/139\n",
      "Participant: 64/139\n",
      "Participant: 65/139\n",
      "Participant: 66/139\n",
      "Participant: 67/139\n",
      "Participant: 68/139\n",
      "Participant: 69/139\n",
      "Participant: 70/139\n",
      "Participant: 71/139\n",
      "Participant: 72/139\n",
      "Participant: 73/139\n",
      "Participant: 74/139\n",
      "Participant: 75/139\n",
      "Participant: 76/139\n",
      "Participant: 77/139\n",
      "Participant: 78/139\n",
      "Participant: 79/139\n",
      "Participant: 80/139\n",
      "Participant: 81/139\n",
      "Participant: 82/139\n",
      "Participant: 83/139\n",
      "Participant: 84/139\n",
      "Participant: 85/139\n",
      "Participant: 86/139\n",
      "Participant: 87/139\n",
      "Participant: 88/139\n",
      "Participant: 89/139\n",
      "Participant: 90/139\n",
      "Participant: 91/139\n",
      "Participant: 92/139\n",
      "Participant: 93/139\n",
      "Participant: 94/139\n",
      "Participant: 95/139\n",
      "Participant: 96/139\n",
      "Participant: 97/139\n",
      "Participant: 98/139\n",
      "Participant: 99/139\n",
      "Participant: 100/139\n",
      "Participant: 101/139\n",
      "Participant: 102/139\n",
      "Participant: 103/139\n",
      "Participant: 104/139\n",
      "Participant: 105/139\n",
      "Participant: 106/139\n",
      "Participant: 107/139\n",
      "Participant: 108/139\n",
      "Participant: 109/139\n",
      "Participant: 110/139\n",
      "Participant: 111/139\n",
      "Participant: 112/139\n",
      "Participant: 113/139\n",
      "Participant: 114/139\n",
      "Participant: 115/139\n",
      "Participant: 116/139\n",
      "Participant: 117/139\n",
      "Participant: 118/139\n",
      "Participant: 119/139\n",
      "Participant: 120/139\n",
      "Participant: 121/139\n",
      "Participant: 122/139\n",
      "Participant: 123/139\n",
      "Participant: 124/139\n",
      "Participant: 125/139\n",
      "Participant: 126/139\n",
      "Participant: 127/139\n",
      "Participant: 128/139\n",
      "Participant: 129/139\n",
      "Participant: 130/139\n",
      "Participant: 131/139\n",
      "Participant: 132/139\n",
      "Participant: 133/139\n",
      "Participant: 134/139\n",
      "Participant: 135/139\n",
      "Participant: 136/139\n",
      "Participant: 137/139\n",
      "Participant: 138/139\n",
      "Participant: 139/139\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Script for formatting the MIT-Long-Term ECG Database\n",
    "\n",
    "Steps:\n",
    "    1. Download the ZIP database from https://physionet.org/content/ltdb/1.0.0/\n",
    "    2. Open it with a zip-opener (WinZip, 7zip).\n",
    "    3. Extract the folder of the same name (named 'mit-bih-long-term-ecg-database-1.0.0') to the same folder as this script.\n",
    "    4. Run this script.\n",
    "\n",
    "Credits:\n",
    "    https://github.com/berndporr/py-ecg-detectors/blob/master/tester_MITDB.py by Bernd Porr\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "\n",
    "data_files = [\"smart/\" + file for file in os.listdir(\"smart\") if \".dat\" in file]\n",
    "\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "# load the .txt file smart/info.txt of the first 140 rows\n",
    "info = pd.read_csv(\"smart/info.txt\", sep=\"\\t\", nrows=140)\n",
    "# add the hearder back to info, Record\tGender\tAge\tWeight\tHeight\tBSA\tBMI\tSmoker\tSBP\tSBP\tIMT MAX\tLVMi\tEF\tVascular event\n",
    "# info.columns = [\"Record\", \"Gender\", \"Age\", \"Weight\", \"Height\", \"BSA\", \"BMI\", \"Smoker\", \"SBP\", \"DBP\", \"IMT_MAX\", \"LVMi\", \"EF\", \"Vascular_event\"] \n",
    "\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "    # extract the record number in file\n",
    "    file_num = str(int(file.split(\"/\")[1].split(\".\")[0]))\n",
    "    \n",
    "    # get the value of Age column in info.txt with the record number equals to file_num\n",
    "    age = info[info[\"Record\"] == file_num][\"Age\"].values[0]\n",
    "    gender = info[info[\"Record\"] == file_num][\"Gender\"].values[0]\n",
    "    \n",
    "    \n",
    "    # Get signal\n",
    "    sample = wfdb.rdsamp(file[:-4])\n",
    "    # print(sample)\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 1]})\n",
    "    \n",
    "    data[\"Participant\"] = \"smart_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 128\n",
    "    data[\"Database\"] = \"smart\"\n",
    "    data[\"Age\"] = age\n",
    "    data[\"Gender\"] = gender\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'qrs')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"smart_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 128\n",
    "    anno[\"Database\"] = \"smart\"\n",
    "    anno[\"Age\"] = age\n",
    "    anno[\"Gender\"] = gender\n",
    "\n",
    "    # Select only 2h of recording (otherwise it's too big)\n",
    "    data = data[460800:460800*3].reset_index(drop=True)\n",
    "    anno = anno[(anno[\"Rpeaks\"] > 460800) & (anno[\"Rpeaks\"] <= 460800*3)].reset_index(drop=True)\n",
    "    anno[\"Rpeaks\"] = anno[\"Rpeaks\"] - 460800\n",
    "    \n",
    "    # Get the p wave features\n",
    "    \n",
    "\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"smart_ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"smart_Rpeaks.csv\", index=False)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "#import neurokit2 as nk\n",
    "#nk.events_plot(anno[\"Rpeaks\"][anno[\"Rpeaks\"] <= 1000], data[\"ECG\"][0:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 139 participants.\n",
      "Processing data for Participant: smart_00\n",
      "Extracted features saved to 'smart_features/smart_features_smart_00.csv'.\n",
      "Processing data for Participant: smart_01\n",
      "Extracted features saved to 'smart_features/smart_features_smart_01.csv'.\n",
      "Processing data for Participant: smart_02\n",
      "Extracted features saved to 'smart_features/smart_features_smart_02.csv'.\n",
      "Processing data for Participant: smart_03\n",
      "Extracted features saved to 'smart_features/smart_features_smart_03.csv'.\n",
      "Processing data for Participant: smart_04\n",
      "Extracted features saved to 'smart_features/smart_features_smart_04.csv'.\n",
      "Processing data for Participant: smart_05\n",
      "Extracted features saved to 'smart_features/smart_features_smart_05.csv'.\n",
      "Processing data for Participant: smart_06\n",
      "Extracted features saved to 'smart_features/smart_features_smart_06.csv'.\n",
      "Processing data for Participant: smart_07\n",
      "Extracted features saved to 'smart_features/smart_features_smart_07.csv'.\n",
      "Processing data for Participant: smart_08\n",
      "Extracted features saved to 'smart_features/smart_features_smart_08.csv'.\n",
      "Processing data for Participant: smart_09\n",
      "Extracted features saved to 'smart_features/smart_features_smart_09.csv'.\n",
      "Processing data for Participant: smart_10\n",
      "Extracted features saved to 'smart_features/smart_features_smart_10.csv'.\n",
      "Processing data for Participant: smart_11\n",
      "Extracted features saved to 'smart_features/smart_features_smart_11.csv'.\n",
      "Processing data for Participant: smart_12\n",
      "Extracted features saved to 'smart_features/smart_features_smart_12.csv'.\n",
      "Processing data for Participant: smart_13\n",
      "Extracted features saved to 'smart_features/smart_features_smart_13.csv'.\n",
      "Processing data for Participant: smart_14\n",
      "Extracted features saved to 'smart_features/smart_features_smart_14.csv'.\n",
      "Processing data for Participant: smart_15\n",
      "Extracted features saved to 'smart_features/smart_features_smart_15.csv'.\n",
      "Processing data for Participant: smart_16\n",
      "Extracted features saved to 'smart_features/smart_features_smart_16.csv'.\n",
      "Processing data for Participant: smart_17\n",
      "Extracted features saved to 'smart_features/smart_features_smart_17.csv'.\n",
      "Processing data for Participant: smart_18\n",
      "Extracted features saved to 'smart_features/smart_features_smart_18.csv'.\n",
      "Processing data for Participant: smart_19\n",
      "Extracted features saved to 'smart_features/smart_features_smart_19.csv'.\n",
      "Processing data for Participant: smart_20\n",
      "Extracted features saved to 'smart_features/smart_features_smart_20.csv'.\n",
      "Processing data for Participant: smart_21\n",
      "Extracted features saved to 'smart_features/smart_features_smart_21.csv'.\n",
      "Processing data for Participant: smart_22\n",
      "Extracted features saved to 'smart_features/smart_features_smart_22.csv'.\n",
      "Processing data for Participant: smart_23\n",
      "Extracted features saved to 'smart_features/smart_features_smart_23.csv'.\n",
      "Processing data for Participant: smart_24\n",
      "Extracted features saved to 'smart_features/smart_features_smart_24.csv'.\n",
      "Processing data for Participant: smart_25\n",
      "Extracted features saved to 'smart_features/smart_features_smart_25.csv'.\n",
      "Processing data for Participant: smart_26\n",
      "Extracted features saved to 'smart_features/smart_features_smart_26.csv'.\n",
      "Processing data for Participant: smart_27\n",
      "Extracted features saved to 'smart_features/smart_features_smart_27.csv'.\n",
      "Processing data for Participant: smart_28\n",
      "Extracted features saved to 'smart_features/smart_features_smart_28.csv'.\n",
      "Processing data for Participant: smart_29\n",
      "Extracted features saved to 'smart_features/smart_features_smart_29.csv'.\n",
      "Processing data for Participant: smart_30\n",
      "Extracted features saved to 'smart_features/smart_features_smart_30.csv'.\n",
      "Processing data for Participant: smart_31\n",
      "Extracted features saved to 'smart_features/smart_features_smart_31.csv'.\n",
      "Processing data for Participant: smart_32\n",
      "Extracted features saved to 'smart_features/smart_features_smart_32.csv'.\n",
      "Processing data for Participant: smart_33\n",
      "Extracted features saved to 'smart_features/smart_features_smart_33.csv'.\n",
      "Processing data for Participant: smart_34\n",
      "Extracted features saved to 'smart_features/smart_features_smart_34.csv'.\n",
      "Processing data for Participant: smart_35\n",
      "Extracted features saved to 'smart_features/smart_features_smart_35.csv'.\n",
      "Processing data for Participant: smart_36\n",
      "Extracted features saved to 'smart_features/smart_features_smart_36.csv'.\n",
      "Processing data for Participant: smart_37\n",
      "Extracted features saved to 'smart_features/smart_features_smart_37.csv'.\n",
      "Processing data for Participant: smart_38\n",
      "Extracted features saved to 'smart_features/smart_features_smart_38.csv'.\n",
      "Processing data for Participant: smart_39\n",
      "Extracted features saved to 'smart_features/smart_features_smart_39.csv'.\n",
      "Processing data for Participant: smart_40\n",
      "Extracted features saved to 'smart_features/smart_features_smart_40.csv'.\n",
      "Processing data for Participant: smart_41\n",
      "Extracted features saved to 'smart_features/smart_features_smart_41.csv'.\n",
      "Processing data for Participant: smart_42\n",
      "Extracted features saved to 'smart_features/smart_features_smart_42.csv'.\n",
      "Processing data for Participant: smart_43\n",
      "Extracted features saved to 'smart_features/smart_features_smart_43.csv'.\n",
      "Processing data for Participant: smart_44\n",
      "Extracted features saved to 'smart_features/smart_features_smart_44.csv'.\n",
      "Processing data for Participant: smart_45\n",
      "Extracted features saved to 'smart_features/smart_features_smart_45.csv'.\n",
      "Processing data for Participant: smart_46\n",
      "Extracted features saved to 'smart_features/smart_features_smart_46.csv'.\n",
      "Processing data for Participant: smart_47\n",
      "Extracted features saved to 'smart_features/smart_features_smart_47.csv'.\n",
      "Processing data for Participant: smart_48\n",
      "Extracted features saved to 'smart_features/smart_features_smart_48.csv'.\n",
      "Processing data for Participant: smart_49\n",
      "Extracted features saved to 'smart_features/smart_features_smart_49.csv'.\n",
      "Processing data for Participant: smart_50\n",
      "Extracted features saved to 'smart_features/smart_features_smart_50.csv'.\n",
      "Processing data for Participant: smart_51\n",
      "Extracted features saved to 'smart_features/smart_features_smart_51.csv'.\n",
      "Processing data for Participant: smart_52\n",
      "Extracted features saved to 'smart_features/smart_features_smart_52.csv'.\n",
      "Processing data for Participant: smart_53\n",
      "Extracted features saved to 'smart_features/smart_features_smart_53.csv'.\n",
      "Processing data for Participant: smart_54\n",
      "Extracted features saved to 'smart_features/smart_features_smart_54.csv'.\n",
      "Processing data for Participant: smart_55\n",
      "Extracted features saved to 'smart_features/smart_features_smart_55.csv'.\n",
      "Processing data for Participant: smart_56\n",
      "Extracted features saved to 'smart_features/smart_features_smart_56.csv'.\n",
      "Processing data for Participant: smart_57\n",
      "Error processing data for Participant: smart_57\n",
      "'[2561] not in index'\n",
      "Processing data for Participant: smart_58\n",
      "Extracted features saved to 'smart_features/smart_features_smart_58.csv'.\n",
      "Processing data for Participant: smart_59\n",
      "Extracted features saved to 'smart_features/smart_features_smart_59.csv'.\n",
      "Processing data for Participant: smart_60\n",
      "Extracted features saved to 'smart_features/smart_features_smart_60.csv'.\n",
      "Processing data for Participant: smart_61\n",
      "Extracted features saved to 'smart_features/smart_features_smart_61.csv'.\n",
      "Processing data for Participant: smart_62\n",
      "Extracted features saved to 'smart_features/smart_features_smart_62.csv'.\n",
      "Processing data for Participant: smart_63\n",
      "Extracted features saved to 'smart_features/smart_features_smart_63.csv'.\n",
      "Processing data for Participant: smart_64\n",
      "Extracted features saved to 'smart_features/smart_features_smart_64.csv'.\n",
      "Processing data for Participant: smart_65\n",
      "Extracted features saved to 'smart_features/smart_features_smart_65.csv'.\n",
      "Processing data for Participant: smart_66\n",
      "Extracted features saved to 'smart_features/smart_features_smart_66.csv'.\n",
      "Processing data for Participant: smart_67\n",
      "Extracted features saved to 'smart_features/smart_features_smart_67.csv'.\n",
      "Processing data for Participant: smart_68\n",
      "Extracted features saved to 'smart_features/smart_features_smart_68.csv'.\n",
      "Processing data for Participant: smart_69\n",
      "Extracted features saved to 'smart_features/smart_features_smart_69.csv'.\n",
      "Processing data for Participant: smart_70\n",
      "Extracted features saved to 'smart_features/smart_features_smart_70.csv'.\n",
      "Processing data for Participant: smart_71\n",
      "Extracted features saved to 'smart_features/smart_features_smart_71.csv'.\n",
      "Processing data for Participant: smart_72\n",
      "Extracted features saved to 'smart_features/smart_features_smart_72.csv'.\n",
      "Processing data for Participant: smart_73\n",
      "Extracted features saved to 'smart_features/smart_features_smart_73.csv'.\n",
      "Processing data for Participant: smart_74\n",
      "Extracted features saved to 'smart_features/smart_features_smart_74.csv'.\n",
      "Processing data for Participant: smart_75\n",
      "Extracted features saved to 'smart_features/smart_features_smart_75.csv'.\n",
      "Processing data for Participant: smart_76\n",
      "Extracted features saved to 'smart_features/smart_features_smart_76.csv'.\n",
      "Processing data for Participant: smart_77\n",
      "Extracted features saved to 'smart_features/smart_features_smart_77.csv'.\n",
      "Processing data for Participant: smart_78\n",
      "Extracted features saved to 'smart_features/smart_features_smart_78.csv'.\n",
      "Processing data for Participant: smart_79\n",
      "Extracted features saved to 'smart_features/smart_features_smart_79.csv'.\n",
      "Processing data for Participant: smart_80\n",
      "Extracted features saved to 'smart_features/smart_features_smart_80.csv'.\n",
      "Processing data for Participant: smart_81\n",
      "Extracted features saved to 'smart_features/smart_features_smart_81.csv'.\n",
      "Processing data for Participant: smart_82\n",
      "Extracted features saved to 'smart_features/smart_features_smart_82.csv'.\n",
      "Processing data for Participant: smart_83\n",
      "Extracted features saved to 'smart_features/smart_features_smart_83.csv'.\n",
      "Processing data for Participant: smart_84\n",
      "Extracted features saved to 'smart_features/smart_features_smart_84.csv'.\n",
      "Processing data for Participant: smart_85\n",
      "Extracted features saved to 'smart_features/smart_features_smart_85.csv'.\n",
      "Processing data for Participant: smart_86\n",
      "Extracted features saved to 'smart_features/smart_features_smart_86.csv'.\n",
      "Processing data for Participant: smart_87\n",
      "Extracted features saved to 'smart_features/smart_features_smart_87.csv'.\n",
      "Processing data for Participant: smart_88\n",
      "Extracted features saved to 'smart_features/smart_features_smart_88.csv'.\n",
      "Processing data for Participant: smart_89\n",
      "Extracted features saved to 'smart_features/smart_features_smart_89.csv'.\n",
      "Processing data for Participant: smart_90\n",
      "Extracted features saved to 'smart_features/smart_features_smart_90.csv'.\n",
      "Processing data for Participant: smart_91\n",
      "Extracted features saved to 'smart_features/smart_features_smart_91.csv'.\n",
      "Processing data for Participant: smart_92\n",
      "Extracted features saved to 'smart_features/smart_features_smart_92.csv'.\n",
      "Processing data for Participant: smart_93\n",
      "Extracted features saved to 'smart_features/smart_features_smart_93.csv'.\n",
      "Processing data for Participant: smart_94\n",
      "Extracted features saved to 'smart_features/smart_features_smart_94.csv'.\n",
      "Processing data for Participant: smart_95\n",
      "Extracted features saved to 'smart_features/smart_features_smart_95.csv'.\n",
      "Processing data for Participant: smart_96\n",
      "Extracted features saved to 'smart_features/smart_features_smart_96.csv'.\n",
      "Processing data for Participant: smart_97\n",
      "Extracted features saved to 'smart_features/smart_features_smart_97.csv'.\n",
      "Processing data for Participant: smart_98\n",
      "Extracted features saved to 'smart_features/smart_features_smart_98.csv'.\n",
      "Processing data for Participant: smart_99\n",
      "Extracted features saved to 'smart_features/smart_features_smart_99.csv'.\n",
      "Processing data for Participant: smart_100\n",
      "Extracted features saved to 'smart_features/smart_features_smart_100.csv'.\n",
      "Processing data for Participant: smart_101\n",
      "Extracted features saved to 'smart_features/smart_features_smart_101.csv'.\n",
      "Processing data for Participant: smart_102\n",
      "Extracted features saved to 'smart_features/smart_features_smart_102.csv'.\n",
      "Processing data for Participant: smart_103\n",
      "Extracted features saved to 'smart_features/smart_features_smart_103.csv'.\n",
      "Processing data for Participant: smart_104\n",
      "Extracted features saved to 'smart_features/smart_features_smart_104.csv'.\n",
      "Processing data for Participant: smart_105\n",
      "Extracted features saved to 'smart_features/smart_features_smart_105.csv'.\n",
      "Processing data for Participant: smart_106\n",
      "Extracted features saved to 'smart_features/smart_features_smart_106.csv'.\n",
      "Processing data for Participant: smart_107\n",
      "Extracted features saved to 'smart_features/smart_features_smart_107.csv'.\n",
      "Processing data for Participant: smart_108\n",
      "Extracted features saved to 'smart_features/smart_features_smart_108.csv'.\n",
      "Processing data for Participant: smart_109\n",
      "Extracted features saved to 'smart_features/smart_features_smart_109.csv'.\n",
      "Processing data for Participant: smart_110\n",
      "Extracted features saved to 'smart_features/smart_features_smart_110.csv'.\n",
      "Processing data for Participant: smart_111\n",
      "Extracted features saved to 'smart_features/smart_features_smart_111.csv'.\n",
      "Processing data for Participant: smart_112\n",
      "Extracted features saved to 'smart_features/smart_features_smart_112.csv'.\n",
      "Processing data for Participant: smart_113\n",
      "Extracted features saved to 'smart_features/smart_features_smart_113.csv'.\n",
      "Processing data for Participant: smart_114\n",
      "Extracted features saved to 'smart_features/smart_features_smart_114.csv'.\n",
      "Processing data for Participant: smart_115\n",
      "Extracted features saved to 'smart_features/smart_features_smart_115.csv'.\n",
      "Processing data for Participant: smart_116\n",
      "Extracted features saved to 'smart_features/smart_features_smart_116.csv'.\n",
      "Processing data for Participant: smart_117\n",
      "Extracted features saved to 'smart_features/smart_features_smart_117.csv'.\n",
      "Processing data for Participant: smart_118\n",
      "Extracted features saved to 'smart_features/smart_features_smart_118.csv'.\n",
      "Processing data for Participant: smart_119\n",
      "Extracted features saved to 'smart_features/smart_features_smart_119.csv'.\n",
      "Processing data for Participant: smart_120\n",
      "Extracted features saved to 'smart_features/smart_features_smart_120.csv'.\n",
      "Processing data for Participant: smart_121\n",
      "Extracted features saved to 'smart_features/smart_features_smart_121.csv'.\n",
      "Processing data for Participant: smart_122\n",
      "Extracted features saved to 'smart_features/smart_features_smart_122.csv'.\n",
      "Processing data for Participant: smart_123\n",
      "Extracted features saved to 'smart_features/smart_features_smart_123.csv'.\n",
      "Processing data for Participant: smart_124\n",
      "Extracted features saved to 'smart_features/smart_features_smart_124.csv'.\n",
      "Processing data for Participant: smart_125\n",
      "Extracted features saved to 'smart_features/smart_features_smart_125.csv'.\n",
      "Processing data for Participant: smart_126\n",
      "Extracted features saved to 'smart_features/smart_features_smart_126.csv'.\n",
      "Processing data for Participant: smart_127\n",
      "Extracted features saved to 'smart_features/smart_features_smart_127.csv'.\n",
      "Processing data for Participant: smart_128\n",
      "Extracted features saved to 'smart_features/smart_features_smart_128.csv'.\n",
      "Processing data for Participant: smart_129\n",
      "Extracted features saved to 'smart_features/smart_features_smart_129.csv'.\n",
      "Processing data for Participant: smart_130\n",
      "Extracted features saved to 'smart_features/smart_features_smart_130.csv'.\n",
      "Processing data for Participant: smart_131\n",
      "Extracted features saved to 'smart_features/smart_features_smart_131.csv'.\n",
      "Processing data for Participant: smart_132\n",
      "Extracted features saved to 'smart_features/smart_features_smart_132.csv'.\n",
      "Processing data for Participant: smart_133\n",
      "Extracted features saved to 'smart_features/smart_features_smart_133.csv'.\n",
      "Processing data for Participant: smart_134\n",
      "Extracted features saved to 'smart_features/smart_features_smart_134.csv'.\n",
      "Processing data for Participant: smart_135\n",
      "Extracted features saved to 'smart_features/smart_features_smart_135.csv'.\n",
      "Processing data for Participant: smart_136\n",
      "Extracted features saved to 'smart_features/smart_features_smart_136.csv'.\n",
      "Processing data for Participant: smart_137\n",
      "Extracted features saved to 'smart_features/smart_features_smart_137.csv'.\n",
      "Processing data for Participant: smart_138\n",
      "Extracted features saved to 'smart_features/smart_features_smart_138.csv'.\n",
      "Processing completed. 1 participants failed to process.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per 20 seconds\n",
    "    samples_per_minute = sample_rate * 20\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "                \n",
    "    for _, group in df_ecg.groupby('Participant'):\n",
    "        for i in range(0, len(group), samples_per_minute):\n",
    "            ecg_segment = group.iloc[i:i+samples_per_minute]\n",
    "            if len(ecg_segment) == samples_per_minute:\n",
    "                features = extract_pqrst_features(ecg_segment['ECG'].values, sample_rate)\n",
    "                features.update({\n",
    "                    'Participant': group['Participant'].iloc[0],\n",
    "                    'Sample': i,\n",
    "                    'Sampling_Rate': sample_rate,\n",
    "                    'Database': group['Database'].iloc[0],\n",
    "                    'Gender': group['Gender'].iloc[0],\n",
    "                    'Age': group['Age'].iloc[0]\n",
    "                })\n",
    "                all_features.append(features)\n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "\n",
    "df_ecg = pd.read_csv(\"smart_ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 128  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"smart_features/smart_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'smart_features/smart_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# # Save the extracted features to a new CSV file\n",
    "# features_df.to_csv(\"smart_features.csv\", index=False)\n",
    "# print(\"Extracted features saved to 'smart_features.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.read_csv(\"smart-ECGs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data of smart_02\n",
    "data = dp[dp[\"Participant\"] == \"smart_02\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check is there any missing value\n",
    "data.to_csv(\"smart_02.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
