{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/7\n",
      "Participant: 2/7\n",
      "Participant: 3/7\n",
      "Participant: 4/7\n",
      "Participant: 5/7\n",
      "Participant: 6/7\n",
      "Participant: 7/7\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Script for formatting the MIT-Long-Term ECG Database\n",
    "\n",
    "Steps:\n",
    "    1. Download the ZIP database from https://physionet.org/content/ltdb/1.0.0/\n",
    "    2. Open it with a zip-opener (WinZip, 7zip).\n",
    "    3. Extract the folder of the same name (named 'mit-bih-long-term-ecg-database-1.0.0') to the same folder as this script.\n",
    "    4. Run this script.\n",
    "\n",
    "Credits:\n",
    "    https://github.com/berndporr/py-ecg-detectors/blob/master/tester_MITDB.py by Bernd Porr\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "\n",
    "data_files = [\"mit-bih-long-term-ecg-database-1.0.0/\" + file for file in os.listdir(\"mit-bih-long-term-ecg-database-1.0.0\") if \".dat\" in file]\n",
    "\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "\n",
    "    # Get signal\n",
    "    sample, fields = wfdb.rdsamp(file[:-4])\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 1]})\n",
    "    gender = fields['comments'][0].split(' ')[4]\n",
    "    # print(gender)\n",
    "    age = int(fields['comments'][0].split(' ')[1])\n",
    "    \n",
    "    data[\"Participant\"] = \"mit-long_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 128\n",
    "    data[\"Database\"] = \"mit-long\"\n",
    "    data[\"Gender\"] = gender\n",
    "    data[\"Age\"] = age\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'atr')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"mit-long_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 128\n",
    "    anno[\"Database\"] = \"mit-long\"\n",
    "    anno[\"Gender\"] = gender\n",
    "    anno[\"Age\"] = age\n",
    "    \n",
    "    # Select only 2h of recording (otherwise it's too big)\n",
    "    data = data[460800:460800*3].reset_index(drop=True)\n",
    "    anno = anno[(anno[\"Rpeaks\"] > 460800) & (anno[\"Rpeaks\"] <= 460800*3)].reset_index(drop=True)\n",
    "    anno[\"Rpeaks\"] = anno[\"Rpeaks\"] - 460800\n",
    "    \n",
    "    # Get the p wave features\n",
    "    \n",
    "\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"mit-long_ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"mit-long_Rpeaks.csv\", index=False)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "#import neurokit2 as nk\n",
    "#nk.events_plot(anno[\"Rpeaks\"][anno[\"Rpeaks\"] <= 1000], data[\"ECG\"][0:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for Participant: MIT-LongTerm_00\n",
      "Processing data for Participant: MIT-LongTerm_01\n",
      "Processing data for Participant: MIT-LongTerm_02\n",
      "Processing data for Participant: MIT-LongTerm_03\n",
      "Processing data for Participant: MIT-LongTerm_04\n",
      "Processing data for Participant: MIT-LongTerm_05\n",
      "Processing data for Participant: MIT-LongTerm_06\n",
      "Extracted features saved to 'MIT_long_features.csv'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 7 participants.\n",
      "Processing data for Participant: mit-long_00\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_00.csv'.\n",
      "Processing data for Participant: mit-long_01\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_01.csv'.\n",
      "Processing data for Participant: mit-long_02\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_02.csv'.\n",
      "Processing data for Participant: mit-long_03\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_03.csv'.\n",
      "Processing data for Participant: mit-long_04\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_04.csv'.\n",
      "Processing data for Participant: mit-long_05\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_05.csv'.\n",
      "Processing data for Participant: mit-long_06\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_06.csv'.\n",
      "Processing completed. 0 participants failed to process.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per 20 seconds\n",
    "    samples_per_minute = sample_rate * 20\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "                \n",
    "    for _, group in df_ecg.groupby('Participant'):\n",
    "        for i in range(0, len(group), samples_per_minute):\n",
    "            ecg_segment = group.iloc[i:i+samples_per_minute]\n",
    "            if len(ecg_segment) == samples_per_minute:\n",
    "                features = extract_pqrst_features(ecg_segment['ECG'].values, sample_rate)\n",
    "                features.update({\n",
    "                    'Participant': group['Participant'].iloc[0],\n",
    "                    'Sample': i,\n",
    "                    'Sampling_Rate': sample_rate,\n",
    "                    'Database': group['Database'].iloc[0],\n",
    "                    'Gender': group['Gender'].iloc[0],\n",
    "                    'Age': group['Age'].iloc[0]\n",
    "                })\n",
    "                all_features.append(features)\n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "df_ecg = pd.read_csv(\"mit-long_ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 128  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    # if participant != \"mit-long_04\":\n",
    "    #     continue\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"mit-long_features/mit-long_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'mit-long_features/mit-long_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        # raise e\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
