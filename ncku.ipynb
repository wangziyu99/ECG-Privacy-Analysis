{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "base_dir = \"NCKU-CBIC-ECG-Database\"\n",
    "\n",
    "combined_ecg_data = []\n",
    "combined_rpeaks_data = []\n",
    "\n",
    "def load_csv_data(filepath):\n",
    "    try:\n",
    "        return pd.read_csv(filepath, header=None).iloc[0]  # Assumes data is in the first row\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load {filepath}: {e}\")\n",
    "        return pd.Series()\n",
    "\n",
    "def is_valid_folder(folder_name):\n",
    "    # Check if the folder name starts with any of the valid prefixes\n",
    "    valid_prefixes = ('1_', '2_', '3_', '4_', '5_', '6_')\n",
    "    return any(folder_name.startswith(prefix) for prefix in valid_prefixes)\n",
    "\n",
    "for participant_folder in os.listdir(base_dir):\n",
    "    if is_valid_folder(participant_folder):  # Check for valid folder names\n",
    "        participant_id = participant_folder.split('_')[0]\n",
    "        formatted_participant_id = f\"NCKU_{participant_id}\" \n",
    "        participant_path = os.path.join(base_dir, participant_folder)\n",
    "        \n",
    "        print(f\"Processing Participant {formatted_participant_id}\")\n",
    "        \n",
    "        if os.path.isdir(participant_path):\n",
    "            ecg_file = os.path.join(participant_path, \"OUTPUT_ECG_data.csv\")\n",
    "            print(ecg_file)\n",
    "            peak_label_file = os.path.join(participant_path, \"OUTPUT_peak_label.csv\")\n",
    "            peak_position_file = os.path.join(participant_path, \"OUTPUT_peak_position.csv\")\n",
    "            \n",
    "            ecg_data = load_csv_data(ecg_file)\n",
    "            peak_labels = load_csv_data(peak_label_file)\n",
    "            peak_positions = load_csv_data(peak_position_file)\n",
    "            \n",
    "            for i, ecg_point in enumerate(ecg_data):\n",
    "                combined_ecg_data.append({\n",
    "                    'Participant': formatted_participant_id,\n",
    "                    'Session': participant_path,\n",
    "                    'Sample': i,\n",
    "                    'ECG': ecg_point,\n",
    "                    'Sampling_Rate': 400\n",
    "                })\n",
    "            \n",
    "            for pos, label in zip(peak_positions, peak_labels):\n",
    "                combined_rpeaks_data.append({\n",
    "                    'Participant': formatted_participant_id,\n",
    "                    'Session': participant_path,\n",
    "                    'Rpeak_Position': pos,\n",
    "                    'Label': label,\n",
    "                    'Sampling_Rate': 400\n",
    "                })\n",
    "\n",
    "df_ecg = pd.DataFrame(combined_ecg_data)\n",
    "df_rpeaks = pd.DataFrame(combined_rpeaks_data)\n",
    "\n",
    "df_ecg.sort_values(by=['Participant', 'Session'], inplace=True)\n",
    "df_rpeaks.sort_values(by=['Participant', 'Session'], inplace=True)\n",
    "\n",
    "df_ecg.to_csv(\"NCKU-ECGs.csv\", index=False)\n",
    "df_rpeaks.to_csv(\"NCKU-Rpeaks.csv\", index=False)\n",
    "\n",
    "print(\"Data processing complete. Files saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per minute\n",
    "    samples_per_minute = sample_rate * 30\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "\n",
    "    # Iterate over each participant's data\n",
    "    # skip the participants with errors when processing\n",
    "    participants = df_ecg['Participant'].unique()\n",
    "    for participant in participants:\n",
    "        # print(f\"Processing data for Participant: {participant}\")\n",
    "        participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "        \n",
    "        # Process data minute by minute\n",
    "        for start in range(0, len(participant_data), samples_per_minute):\n",
    "            end = start + samples_per_minute\n",
    "            ecg_segment = participant_data['ECG'].iloc[start:end].values\n",
    "\n",
    "            if len(ecg_segment) == samples_per_minute:  # Ensure full minute data \n",
    "                features = extract_pqrst_features(ecg_segment, sample_rate)\n",
    "                features.update({'Participant': participant, 'Half Minute': start // samples_per_minute})\n",
    "                all_features.append(features)\n",
    "        \n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "\n",
    "df_ecg = pd.read_csv(\"NCKU-ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 400  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"NCKU_features/NCKU_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'NCKU_features/NCKU_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 6 participants.\n",
      "Processing data for Participant: NCKU_1\n",
      "  Participant                        Session  Sample       ECG  Sampling_Rate\n",
      "0      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       0 -0.004349            400\n",
      "1      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       1 -0.010554            400\n",
      "2      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       2 -0.012562            400\n",
      "3      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       3 -0.012562            400\n",
      "4      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       4 -0.012562            400\n",
      "  Participant                        Session  Sample       ECG  Sampling_Rate  \\\n",
      "0      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       0 -0.004349            400   \n",
      "1      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       1 -0.010554            400   \n",
      "2      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       2 -0.012562            400   \n",
      "3      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       3 -0.012562            400   \n",
      "4      NCKU_1  NCKU-CBIC-ECG-Database/1_0100       4 -0.012562            400   \n",
      "\n",
      "   Cleaned_ECG  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_1.csv'.\n",
      "Processing data for Participant: NCKU_2\n",
      "        Participant                        Session  Sample       ECG  \\\n",
      "5907936      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       0 -0.002446   \n",
      "5907937      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       1 -0.006647   \n",
      "5907938      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       2 -0.011462   \n",
      "5907939      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       3 -0.011462   \n",
      "5907940      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       4 -0.011462   \n",
      "\n",
      "         Sampling_Rate  \n",
      "5907936            400  \n",
      "5907937            400  \n",
      "5907938            400  \n",
      "5907939            400  \n",
      "5907940            400  \n",
      "        Participant                        Session  Sample       ECG  \\\n",
      "5907936      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       0 -0.002446   \n",
      "5907937      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       1 -0.006647   \n",
      "5907938      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       2 -0.011462   \n",
      "5907939      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       3 -0.011462   \n",
      "5907940      NCKU_2  NCKU-CBIC-ECG-Database/2_0100       4 -0.011462   \n",
      "\n",
      "         Sampling_Rate  Cleaned_ECG  \n",
      "5907936            400          NaN  \n",
      "5907937            400          NaN  \n",
      "5907938            400          NaN  \n",
      "5907939            400          NaN  \n",
      "5907940            400          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_2.csv'.\n",
      "Processing data for Participant: NCKU_3\n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "11806866      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       0 -0.001012   \n",
      "11806867      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       1 -0.002310   \n",
      "11806868      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       2 -0.002384   \n",
      "11806869      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       3 -0.002384   \n",
      "11806870      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       4 -0.002384   \n",
      "\n",
      "          Sampling_Rate  \n",
      "11806866            400  \n",
      "11806867            400  \n",
      "11806868            400  \n",
      "11806869            400  \n",
      "11806870            400  \n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "11806866      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       0 -0.001012   \n",
      "11806867      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       1 -0.002310   \n",
      "11806868      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       2 -0.002384   \n",
      "11806869      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       3 -0.002384   \n",
      "11806870      NCKU_3  NCKU-CBIC-ECG-Database/3_0000       4 -0.002384   \n",
      "\n",
      "          Sampling_Rate  Cleaned_ECG  \n",
      "11806866            400          NaN  \n",
      "11806867            400          NaN  \n",
      "11806868            400          NaN  \n",
      "11806869            400          NaN  \n",
      "11806870            400          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_3.csv'.\n",
      "Processing data for Participant: NCKU_4\n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "17720806      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       0  0.000814   \n",
      "17720807      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       1  0.001821   \n",
      "17720808      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       2  0.002524   \n",
      "17720809      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       3  0.002524   \n",
      "17720810      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       4  0.002524   \n",
      "\n",
      "          Sampling_Rate  \n",
      "17720806            400  \n",
      "17720807            400  \n",
      "17720808            400  \n",
      "17720809            400  \n",
      "17720810            400  \n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "17720806      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       0  0.000814   \n",
      "17720807      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       1  0.001821   \n",
      "17720808      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       2  0.002524   \n",
      "17720809      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       3  0.002524   \n",
      "17720810      NCKU_4  NCKU-CBIC-ECG-Database/4_0000       4  0.002524   \n",
      "\n",
      "          Sampling_Rate  Cleaned_ECG  \n",
      "17720806            400          NaN  \n",
      "17720807            400          NaN  \n",
      "17720808            400          NaN  \n",
      "17720809            400          NaN  \n",
      "17720810            400          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_4.csv'.\n",
      "Processing data for Participant: NCKU_5\n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "23613732      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       0 -0.006177   \n",
      "23613733      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       1 -0.015276   \n",
      "23613734      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       2 -0.018831   \n",
      "23613735      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       3 -0.018831   \n",
      "23613736      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       4 -0.018831   \n",
      "\n",
      "          Sampling_Rate  \n",
      "23613732            400  \n",
      "23613733            400  \n",
      "23613734            400  \n",
      "23613735            400  \n",
      "23613736            400  \n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "23613732      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       0 -0.006177   \n",
      "23613733      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       1 -0.015276   \n",
      "23613734      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       2 -0.018831   \n",
      "23613735      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       3 -0.018831   \n",
      "23613736      NCKU_5  NCKU-CBIC-ECG-Database/5_0200       4 -0.018831   \n",
      "\n",
      "          Sampling_Rate  Cleaned_ECG  \n",
      "23613732            400          NaN  \n",
      "23613733            400          NaN  \n",
      "23613734            400          NaN  \n",
      "23613735            400          NaN  \n",
      "23613736            400          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_5.csv'.\n",
      "Processing data for Participant: NCKU_6\n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "29506996      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       0 -0.018309   \n",
      "29506997      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       1 -0.045779   \n",
      "29506998      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       2 -0.056813   \n",
      "29506999      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       3 -0.056813   \n",
      "29507000      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       4 -0.056813   \n",
      "\n",
      "          Sampling_Rate  \n",
      "29506996            400  \n",
      "29506997            400  \n",
      "29506998            400  \n",
      "29506999            400  \n",
      "29507000            400  \n",
      "         Participant                        Session  Sample       ECG  \\\n",
      "29506996      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       0 -0.018309   \n",
      "29506997      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       1 -0.045779   \n",
      "29506998      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       2 -0.056813   \n",
      "29506999      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       3 -0.056813   \n",
      "29507000      NCKU_6  NCKU-CBIC-ECG-Database/6_0000       4 -0.056813   \n",
      "\n",
      "          Sampling_Rate  Cleaned_ECG  \n",
      "29506996            400          NaN  \n",
      "29506997            400          NaN  \n",
      "29506998            400          NaN  \n",
      "29506999            400          NaN  \n",
      "29507000            400          NaN  \n",
      "Extracted features saved to 'NCKU_features/NCKU_features_NCKU_6.csv'.\n",
      "Processing completed. 0 participants failed to process.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "def clean_ecg_data(participant_data, sample_rate):\n",
    "    \"\"\"\n",
    "    Clean the ECG signal using NeuroKit2 for each row and add as a new column.\n",
    "    Assumes 'ECG' column contains raw ECG data possibly as a comma-separated string.\n",
    "    \"\"\"\n",
    "    # Ensure that each ECG entry is an np.array; handle strings or NaNs appropriately\n",
    "    def to_float_array(ecg):\n",
    "        if isinstance(ecg, str):\n",
    "            try:\n",
    "                return np.fromstring(ecg, sep=',')\n",
    "            except:\n",
    "                return np.nan  # Return NaN if conversion fails\n",
    "        return ecg  # Return the array if already in correct format\n",
    "\n",
    "    participant_data['ECG'] = participant_data['ECG'].apply(to_float_array)\n",
    "\n",
    "    # Clean ECG data only if it's not NaN and length is sufficient\n",
    "    def clean_if_possible(ecg):\n",
    "        if isinstance(ecg, np.ndarray) and len(ecg) > sample_rate / 2:\n",
    "            return nk.ecg_clean(ecg, sampling_rate=sample_rate)\n",
    "        return np.nan  # Return NaN if too short or not proper np.ndarray\n",
    "\n",
    "    participant_data['Cleaned_ECG'] = participant_data['ECG'].apply(clean_if_possible)\n",
    "    return participant_data\n",
    "\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per minute\n",
    "    samples_per_minute = sample_rate * 30\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "\n",
    "    # Iterate over each participant's data\n",
    "    # skip the participants with errors when processing\n",
    "    participants = df_ecg['Participant'].unique()\n",
    "    for participant in participants:\n",
    "        # print(f\"Processing data for Participant: {participant}\")\n",
    "        participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "        \n",
    "        print(participant_data.head())\n",
    "        \n",
    "        participant_data = clean_ecg_data(participant_data, sample_rate)\n",
    "        \n",
    "        print(participant_data.head())\n",
    "    \n",
    "        # Process data minute by minute\n",
    "        for start in range(0, len(participant_data), samples_per_minute):\n",
    "            end = start + samples_per_minute\n",
    "            ecg_segment = participant_data['ECG'].iloc[start:end].values\n",
    "\n",
    "            if len(ecg_segment) == samples_per_minute:  # Ensure full minute data \n",
    "                features = extract_pqrst_features(ecg_segment, sample_rate)\n",
    "                features.update({'Participant': participant, 'Half Minute': start // samples_per_minute})\n",
    "                all_features.append(features)\n",
    "        \n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "\n",
    "df_ecg = pd.read_csv(\"NCKU-ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 400  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"NCKU_features/NCKU_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'NCKU_features/NCKU_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        # raise e\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
