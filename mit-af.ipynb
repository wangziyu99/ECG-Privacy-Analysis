{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/23\n",
      "    label_store symbol                                    description\n",
      "0             0                              Not an actual annotation\n",
      "1             1      N                                    Normal beat\n",
      "2             2      L                  Left bundle branch block beat\n",
      "3             3      R                 Right bundle branch block beat\n",
      "4             4      a                Aberrated atrial premature beat\n",
      "5             5      V              Premature ventricular contraction\n",
      "6             6      F          Fusion of ventricular and normal beat\n",
      "7             7      J              Nodal (junctional) premature beat\n",
      "8             8      A                   Atrial premature contraction\n",
      "9             9      S     Premature or ectopic supraventricular beat\n",
      "10           10      E                        Ventricular escape beat\n",
      "11           11      j                 Nodal (junctional) escape beat\n",
      "12           12      /                                     Paced beat\n",
      "13           13      Q                            Unclassifiable beat\n",
      "14           14      ~                          Signal quality change\n",
      "16           16      |                     Isolated QRS-like artifact\n",
      "18           18      s                                      ST change\n",
      "19           19      T                                  T-wave change\n",
      "20           20      *                                        Systole\n",
      "21           21      D                                       Diastole\n",
      "22           22      \"                             Comment annotation\n",
      "23           23      =                         Measurement annotation\n",
      "24           24      p                                    P-wave peak\n",
      "25           25      B              Left or right bundle branch block\n",
      "26           26      ^                      Non-conducted pacer spike\n",
      "27           27      t                                    T-wave peak\n",
      "28           28      +                                  Rhythm change\n",
      "29           29      u                                    U-wave peak\n",
      "30           30      ?                                       Learning\n",
      "31           31      !                       Ventricular flutter wave\n",
      "32           32      [      Start of ventricular flutter/fibrillation\n",
      "33           33      ]        End of ventricular flutter/fibrillation\n",
      "34           34      e                             Atrial escape beat\n",
      "35           35      n                   Supraventricular escape beat\n",
      "36           36      @  Link to external data (aux_note contains URL)\n",
      "37           37      x             Non-conducted P-wave (blocked APB)\n",
      "38           38      f                Fusion of paced and normal beat\n",
      "39           39      (                                 Waveform onset\n",
      "40           40      )                                   Waveform end\n",
      "41           41      r       R-on-T premature ventricular contraction\n",
      "None\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m anno[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSampling_Rate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m250\u001b[39m\n\u001b[1;32m     55\u001b[0m anno[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatabase\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmit-af\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 56\u001b[0m anno[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGender\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgender\u001b[49m\n\u001b[1;32m     57\u001b[0m anno[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m age\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Select only 2h of recording (otherwise it's too big)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gender' is not defined"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Script for formatting the MIT-Long-Term ECG Database\n",
    "\n",
    "Steps:\n",
    "    1. Download the ZIP database from https://physionet.org/content/ltdb/1.0.0/\n",
    "    2. Open it with a zip-opener (WinZip, 7zip).\n",
    "    3. Extract the folder of the same name (named 'mit-bih-long-term-ecg-database-1.0.0') to the same folder as this script.\n",
    "    4. Run this script.\n",
    "\n",
    "Credits:\n",
    "    https://github.com/berndporr/py-ecg-detectors/blob/master/tester_MITDB.py by Bernd Porr\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "\n",
    "data_files = [\"mit-bih-atrial-fibrillation-database-1.0.0/\" + file for file in os.listdir(\"mit-bih-atrial-fibrillation-database-1.0.0/\") if \".dat\" in file]\n",
    "\n",
    "\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "\n",
    "    # Get signal\n",
    "    sample, fields = wfdb.rdsamp(file[:-4])\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 1]})\n",
    "    # print(fields)\n",
    "    # gender = fields['comments'][0].split(' ')[4]\n",
    "    # # print(gender)\n",
    "    # age = int(fields['comments'][0].split(' ')[1])\n",
    "    \n",
    "    # print(\"Age: \" + str(age))\n",
    "    # print(\"Gender: \" + str(gender))\n",
    "    \n",
    "    data[\"Participant\"] = \"mit-af_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 250\n",
    "    data[\"Database\"] = \"mit-af\"\n",
    "    # data[\"Gender\"] = gender\n",
    "    # data[\"Age\"] = age\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'atr')\n",
    "    print(wfdb.show_ann_labels())\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"mit-af_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 250\n",
    "    anno[\"Database\"] = \"mit-af\"\n",
    "    anno[\"Gender\"] = gender\n",
    "    anno[\"Age\"] = age\n",
    "    \n",
    "    # Select only 2h of recording (otherwise it's too big)\n",
    "    data = data[460800:460800*3].reset_index(drop=True)\n",
    "    anno = anno[(anno[\"Rpeaks\"] > 460800) & (anno[\"Rpeaks\"] <= 460800*3)].reset_index(drop=True)\n",
    "    anno[\"Rpeaks\"] = anno[\"Rpeaks\"] - 460800\n",
    "    \n",
    "    # Get the p wave features\n",
    "    \n",
    "\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"mit-af_ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"mit-af_Rpeaks.csv\", index=False)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "#import neurokit2 as nk\n",
    "#nk.events_plot(anno[\"Rpeaks\"][anno[\"Rpeaks\"] <= 1000], data[\"ECG\"][0:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for Participant: MIT-LongTerm_00\n",
      "Processing data for Participant: MIT-LongTerm_01\n",
      "Processing data for Participant: MIT-LongTerm_02\n",
      "Processing data for Participant: MIT-LongTerm_03\n",
      "Processing data for Participant: MIT-LongTerm_04\n",
      "Processing data for Participant: MIT-LongTerm_05\n",
      "Processing data for Participant: MIT-LongTerm_06\n",
      "Extracted features saved to 'MIT_long_features.csv'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 7 participants.\n",
      "Processing data for Participant: mit-long_00\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_00.csv'.\n",
      "Processing data for Participant: mit-long_01\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_01.csv'.\n",
      "Processing data for Participant: mit-long_02\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_02.csv'.\n",
      "Processing data for Participant: mit-long_03\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_03.csv'.\n",
      "Processing data for Participant: mit-long_04\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_04.csv'.\n",
      "Processing data for Participant: mit-long_05\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_05.csv'.\n",
      "Processing data for Participant: mit-long_06\n",
      "Extracted features saved to 'mit-long_features/mit-long_features_mit-long_06.csv'.\n",
      "Processing completed. 0 participants failed to process.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per 20 seconds\n",
    "    samples_per_minute = sample_rate * 20\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "                \n",
    "    for _, group in df_ecg.groupby('Participant'):\n",
    "        for i in range(0, len(group), samples_per_minute):\n",
    "            ecg_segment = group.iloc[i:i+samples_per_minute]\n",
    "            if len(ecg_segment) == samples_per_minute:\n",
    "                features = extract_pqrst_features(ecg_segment['ECG'].values, sample_rate)\n",
    "                features.update({\n",
    "                    'Participant': group['Participant'].iloc[0],\n",
    "                    'Sample': i,\n",
    "                    'Sampling_Rate': sample_rate,\n",
    "                    'Database': group['Database'].iloc[0],\n",
    "                    'Gender': group['Gender'].iloc[0],\n",
    "                    'Age': group['Age'].iloc[0]\n",
    "                })\n",
    "                all_features.append(features)\n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "df_ecg = pd.read_csv(\"mit-long_ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 128  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    # if participant != \"mit-long_04\":\n",
    "    #     continue\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"mit-long_features/mit-long_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'mit-long_features/mit-long_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        # raise e\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
