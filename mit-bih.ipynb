{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant: 1/48\n",
      "Participant: 2/48\n",
      "Participant: 3/48\n",
      "Participant: 4/48\n",
      "Participant: 5/48\n",
      "Participant: 6/48\n",
      "Participant: 7/48\n",
      "Participant: 8/48\n",
      "Participant: 9/48\n",
      "Participant: 10/48\n",
      "Participant: 11/48\n",
      "Participant: 12/48\n",
      "Participant: 13/48\n",
      "Participant: 14/48\n",
      "Participant: 15/48\n",
      "Participant: 16/48\n",
      "Participant: 17/48\n",
      "Participant: 18/48\n",
      "Participant: 19/48\n",
      "Participant: 20/48\n",
      "Participant: 21/48\n",
      "Participant: 22/48\n",
      "Participant: 23/48\n",
      "Participant: 24/48\n",
      "Participant: 25/48\n",
      "Participant: 26/48\n",
      "Participant: 27/48\n",
      "Participant: 28/48\n",
      "Participant: 29/48\n",
      "Participant: 30/48\n",
      "Participant: 31/48\n",
      "Participant: 32/48\n",
      "Participant: 33/48\n",
      "Participant: 34/48\n",
      "Participant: 35/48\n",
      "Participant: 36/48\n",
      "Participant: 37/48\n",
      "Participant: 38/48\n",
      "Participant: 39/48\n",
      "Participant: 40/48\n",
      "Participant: 41/48\n",
      "Participant: 42/48\n",
      "Participant: 43/48\n",
      "Participant: 44/48\n",
      "Participant: 45/48\n",
      "Participant: 46/48\n",
      "Participant: 47/48\n",
      "Participant: 48/48\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Script for formatting the MIT-Long-Term ECG Database\n",
    "\n",
    "Steps:\n",
    "    1. Download the ZIP database from https://physionet.org/content/ltdb/1.0.0/\n",
    "    2. Open it with a zip-opener (WinZip, 7zip).\n",
    "    3. Extract the folder of the same name (named 'mit-bih-long-term-ecg-database-1.0.0') to the same folder as this script.\n",
    "    4. Run this script.\n",
    "\n",
    "Credits:\n",
    "    https://github.com/berndporr/py-ecg-detectors/blob/master/tester_MITDB.py by Bernd Porr\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wfdb\n",
    "\n",
    "data_files = [\"mit-bih-arrhythmia-database-1.0.0/\" + file for file in os.listdir(\"mit-bih-arrhythmia-database-1.0.0/\") if \".dat\" in file]\n",
    "\n",
    "dfs_ecg = []\n",
    "dfs_rpeaks = []\n",
    "\n",
    "for participant, file in enumerate(data_files):\n",
    "    print(\"Participant: \" + str(participant + 1) + \"/\" + str(len(data_files)))\n",
    "\n",
    "    # Get signal\n",
    "    sample, fields = wfdb.rdsamp(file[:-4])\n",
    "    data = pd.DataFrame({\"ECG\": wfdb.rdsamp(file[:-4])[0][:, 1]})\n",
    "    \n",
    "    gender = fields['comments'][0].split(' ')[1]\n",
    "    age = int(fields['comments'][0].split(' ')[0])\n",
    "    \n",
    "    data[\"Participant\"] = \"mit-bih_%.2i\" %(participant)\n",
    "    data[\"Sample\"] = range(len(data))\n",
    "    data[\"Sampling_Rate\"] = 360\n",
    "    data[\"Database\"] = \"mit-bih\"\n",
    "    data[\"Gender\"] = gender\n",
    "    data[\"Age\"] = age\n",
    "\n",
    "    # getting annotations\n",
    "    anno = wfdb.rdann(file[:-4], 'atr')\n",
    "    anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "    anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "    anno[\"Participant\"] = \"mit-bih_%.2i\" %(participant)\n",
    "    anno[\"Sampling_Rate\"] = 360\n",
    "    anno[\"Database\"] = \"mit-bih\"\n",
    "    anno[\"Gender\"] = gender\n",
    "    anno[\"Age\"] = age\n",
    "\n",
    "    # Select only 2h of recording (otherwise it's too big)\n",
    "    # data = data[460800:460800*3].reset_index(drop=True)\n",
    "    # anno = anno[(anno[\"Rpeaks\"] > 460800) & (anno[\"Rpeaks\"] <= 460800*3)].reset_index(drop=True)\n",
    "    # anno[\"Rpeaks\"] = anno[\"Rpeaks\"] - 460800\n",
    "    \n",
    "    # Get the p wave features\n",
    "    \n",
    "    additional_path = \"mit-bih-arrhythmia-database-1.0.0/\" + \"x_mitdb/\"\n",
    "    # print(file.replace(\"mit-bih-arrhythmia-database-1.0.0/\", \"\"))\n",
    "    additional_file = additional_path + \"x_\" + file.replace(\"mit-bih-arrhythmia-database-1.0.0/\", \"\")\n",
    "    if additional_file in os.listdir(additional_path):\n",
    "        print(\"  - Additional recording detected.\")\n",
    "        additional_sample, additional_fields = wfdb.rdsamp(additional_file[:-4])\n",
    "        additional_data = pd.DataFrame({\"ECG\": wfdb.rdsamp(additional_file[:-4])[0][:, 1]})\n",
    "        \n",
    "        additional_gender = additional_fields['comments'][0].split(' ')[1]\n",
    "        additional_age = int(additional_fields['comments'][0].split(' ')[0])\n",
    "        \n",
    "        additional_data[\"Participant\"] = \"mit-bih_%.2i\" %(participant)\n",
    "        additional_data[\"Sample\"] = range(len(data))\n",
    "        additional_data[\"Sampling_Rate\"] = 360\n",
    "        additional_data[\"Database\"] = \"mit-bih\"\n",
    "        additional_data[\"Gender\"] = additional_gender\n",
    "        additional_data[\"Age\"] = additional_age\n",
    "\n",
    "        # getting annotations\n",
    "        additional_anno = wfdb.rdann(additional_file[:-4], 'atr')\n",
    "        additional_anno = anno.sample[np.where(np.array(anno.symbol) == \"N\")[0]]\n",
    "        additional_anno = pd.DataFrame({\"Rpeaks\": anno})\n",
    "        additional_anno[\"Participant\"] = \"mit-bih_%.2i\" %(participant)\n",
    "        additional_anno[\"Sampling_Rate\"] = 360\n",
    "        additional_anno[\"Database\"] = \"mit-bih\"\n",
    "        additional_anno[\"Gender\"] = additional_gender\n",
    "        additional_anno[\"Age\"] = additional_age\n",
    "        # Concatenate the dataframes with their respective dataframes\n",
    "        \n",
    "        data = pd.concat([data, additional_data], ignore_index=True)\n",
    "        anno = pd.concat([anno, additional_anno], ignore_index=True)\n",
    "\n",
    "    # Store with the rest\n",
    "    dfs_ecg.append(data)\n",
    "    dfs_rpeaks.append(anno)\n",
    "\n",
    "# Save\n",
    "df_ecg = pd.concat(dfs_ecg).to_csv(\"mit-bih_ECGs.csv\", index=False)\n",
    "dfs_rpeaks = pd.concat(dfs_rpeaks).to_csv(\"mit-bih_Rpeaks.csv\", index=False)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "#import neurokit2 as nk\n",
    "#nk.events_plot(anno[\"Rpeaks\"][anno[\"Rpeaks\"] <= 1000], data[\"ECG\"][0:1001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 48 participants.\n",
      "Processing data for Participant: mit-bih_00\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_00.csv'.\n",
      "Processing data for Participant: mit-bih_01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data for Participant: mit-bih_01\n",
      "cannot convert float NaN to integer\n",
      "Processing data for Participant: mit-bih_02\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_02.csv'.\n",
      "Processing data for Participant: mit-bih_03\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_03.csv'.\n",
      "Processing data for Participant: mit-bih_04\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_04.csv'.\n",
      "Processing data for Participant: mit-bih_05\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_05.csv'.\n",
      "Processing data for Participant: mit-bih_06\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_06.csv'.\n",
      "Processing data for Participant: mit-bih_07\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_07.csv'.\n",
      "Processing data for Participant: mit-bih_08\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_08.csv'.\n",
      "Processing data for Participant: mit-bih_09\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_09.csv'.\n",
      "Processing data for Participant: mit-bih_10\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_10.csv'.\n",
      "Processing data for Participant: mit-bih_11\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_11.csv'.\n",
      "Processing data for Participant: mit-bih_12\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_12.csv'.\n",
      "Processing data for Participant: mit-bih_13\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_13.csv'.\n",
      "Processing data for Participant: mit-bih_14\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_14.csv'.\n",
      "Processing data for Participant: mit-bih_15\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_15.csv'.\n",
      "Processing data for Participant: mit-bih_16\n",
      "Error processing data for Participant: mit-bih_16\n",
      "cannot convert float NaN to integer\n",
      "Processing data for Participant: mit-bih_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n",
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data for Participant: mit-bih_17\n",
      "cannot convert float NaN to integer\n",
      "Processing data for Participant: mit-bih_18\n",
      "Error processing data for Participant: mit-bih_18\n",
      "'[7207] not in index'\n",
      "Processing data for Participant: mit-bih_19\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_19.csv'.\n",
      "Processing data for Participant: mit-bih_20\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_20.csv'.\n",
      "Processing data for Participant: mit-bih_21\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_21.csv'.\n",
      "Processing data for Participant: mit-bih_22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data for Participant: mit-bih_22\n",
      "cannot convert float NaN to integer\n",
      "Processing data for Participant: mit-bih_23\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_23.csv'.\n",
      "Processing data for Participant: mit-bih_24\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_24.csv'.\n",
      "Processing data for Participant: mit-bih_25\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_25.csv'.\n",
      "Processing data for Participant: mit-bih_26\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_26.csv'.\n",
      "Processing data for Participant: mit-bih_27\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_27.csv'.\n",
      "Processing data for Participant: mit-bih_28\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_28.csv'.\n",
      "Processing data for Participant: mit-bih_29\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_29.csv'.\n",
      "Processing data for Participant: mit-bih_30\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_30.csv'.\n",
      "Processing data for Participant: mit-bih_31\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_31.csv'.\n",
      "Processing data for Participant: mit-bih_32\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_32.csv'.\n",
      "Processing data for Participant: mit-bih_33\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_33.csv'.\n",
      "Processing data for Participant: mit-bih_34\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_34.csv'.\n",
      "Processing data for Participant: mit-bih_35\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_35.csv'.\n",
      "Processing data for Participant: mit-bih_36\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_36.csv'.\n",
      "Processing data for Participant: mit-bih_37\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_37.csv'.\n",
      "Processing data for Participant: mit-bih_38\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_38.csv'.\n",
      "Processing data for Participant: mit-bih_39\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_39.csv'.\n",
      "Processing data for Participant: mit-bih_40\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_40.csv'.\n",
      "Processing data for Participant: mit-bih_41\n",
      "Error processing data for Participant: mit-bih_41\n",
      "'[7208] not in index'\n",
      "Processing data for Participant: mit-bih_42\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_42.csv'.\n",
      "Processing data for Participant: mit-bih_43\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_43.csv'.\n",
      "Processing data for Participant: mit-bih_44\n",
      "Error processing data for Participant: mit-bih_44\n",
      "'[7201] not in index'\n",
      "Processing data for Participant: mit-bih_45\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_45.csv'.\n",
      "Processing data for Participant: mit-bih_46\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_46.csv'.\n",
      "Processing data for Participant: mit-bih_47\n",
      "Extracted features saved to 'mit-bih_features/mit-bih_features_mit-bih_47.csv'.\n",
      "Processing completed. 7 participants failed to process.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per 20 seconds\n",
    "    samples_per_minute = sample_rate * 20\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "                \n",
    "    for _, group in df_ecg.groupby('Participant'):\n",
    "        for i in range(0, len(group), samples_per_minute):\n",
    "            ecg_segment = group.iloc[i:i+samples_per_minute]\n",
    "            if len(ecg_segment) == samples_per_minute:\n",
    "                features = extract_pqrst_features(ecg_segment['ECG'].values, sample_rate)\n",
    "                features.update({\n",
    "                    'Participant': group['Participant'].iloc[0],\n",
    "                    'Sample': i,\n",
    "                    'Sampling_Rate': sample_rate,\n",
    "                    'Database': group['Database'].iloc[0],\n",
    "                    'Gender': group['Gender'].iloc[0],\n",
    "                    'Age': group['Age'].iloc[0]\n",
    "                })\n",
    "                all_features.append(features)\n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "df_ecg = pd.read_csv(\"mit-bih_ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 360  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    print(f\"Processing data for Participant: {participant}\")\n",
    "    participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "    try:\n",
    "        features = process_ecg_data(participant_data, sample_rate)\n",
    "        # Save the extracted features to a new CSV file\n",
    "        features.to_csv(f\"mit-bih_features/mit-bih_features_{participant}.csv\", index=False)\n",
    "        print(f\"Extracted features saved to 'mit-bih_features/mit-bih_features_{participant}.csv'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data for Participant: {participant}\")\n",
    "        print(e)\n",
    "        # raise e\n",
    "        failed += 1\n",
    "print(f\"Processing completed. {failed} participants failed to process.\")\n",
    "\n",
    "mit-bih_01, mit-bih_16, mit-bih_17, mit-bih_18, mit-bih_22, mit-bih_41, mit-bih_44 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for 48 participants.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing completed. 0 participants failed to process.\n",
      "Processing data for Participant: mit-bih_16\n",
      "Error processing data for Participant: mit-bih_16\n",
      "cannot convert float NaN to integer\n",
      "Processing completed. 1 participants failed to process.\n",
      "Processing data for Participant: mit-bih_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing data for Participant: mit-bih_17\n",
      "cannot convert float NaN to integer\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n",
      "Processing completed. 2 participants failed to process.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ziyuwang/anaconda3/envs/ecg/lib/python3.12/site-packages/neurokit2/signal/signal_period.py:84: NeuroKitWarning: Too few peaks detected to compute the rate. Returning empty vector.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "\n",
    "def extract_pqrst_features(ecg_signal, sample_rate):\n",
    "    cleaned_ecg = nk.ecg_clean(ecg_signal, sampling_rate=sample_rate)\n",
    "    _, rpeaks = nk.ecg_peaks(cleaned_ecg, sampling_rate=sample_rate)\n",
    "    _, waves_peak = nk.ecg_delineate(cleaned_ecg, rpeaks, sampling_rate=sample_rate, method=\"peak\")\n",
    "\n",
    "    # Initialize dictionary to store features\n",
    "    features = {}\n",
    "\n",
    "    # Check and calculate amplitude differences where indices are valid\n",
    "    def calculate_amplitude_differences(peak_indices, reference_peak_indices):\n",
    "        valid_indices = [i for i in range(len(peak_indices)) if not math.isnan(peak_indices[i]) and not math.isnan(reference_peak_indices[i])]\n",
    "        amplitudes = np.array([cleaned_ecg[int(peak_indices[i])] - cleaned_ecg[int(reference_peak_indices[i])] for i in valid_indices])\n",
    "        return np.mean(amplitudes[~np.isnan(amplitudes)]) if amplitudes.size > 0 else np.nan\n",
    "\n",
    "    # Calculate amplitude differences for P, Q, S, T peaks with respect to R-peaks\n",
    "    features['P_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_P_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['Q_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['S_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_S_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['T_minus_R_amp_mean'] = calculate_amplitude_differences(waves_peak['ECG_T_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "\n",
    "    # Calculate interval features\n",
    "    def calculate_intervals(start_peaks, end_peaks):\n",
    "        valid_indices = [i for i in range(len(start_peaks)) if not math.isnan(start_peaks[i]) and not math.isnan(end_peaks[i])]\n",
    "        intervals = np.array([(end_peaks[i] - start_peaks[i]) / sample_rate for i in valid_indices])  # convert to seconds\n",
    "        return np.mean(intervals[~np.isnan(intervals)]) if intervals.size > 0 else np.nan\n",
    "\n",
    "    features['PQ_interval_mean'] = calculate_intervals(waves_peak['ECG_P_Onsets'], waves_peak['ECG_Q_Peaks'])\n",
    "    features['QR_interval_mean'] = calculate_intervals(waves_peak['ECG_Q_Peaks'], rpeaks['ECG_R_Peaks'])\n",
    "    features['RS_interval_mean'] = calculate_intervals(rpeaks['ECG_R_Peaks'], waves_peak['ECG_S_Peaks'])\n",
    "    features['ST_interval_mean'] = calculate_intervals(waves_peak['ECG_S_Peaks'], waves_peak['ECG_T_Peaks'])\n",
    "\n",
    "    return features\n",
    "\n",
    "import math\n",
    "\n",
    "def process_ecg_data(df_ecg, sample_rate):\n",
    "    # Determine the number of samples per 20 seconds\n",
    "    samples_per_minute = sample_rate * 24\n",
    "\n",
    "    # Prepare to collect all features\n",
    "    all_features = []\n",
    "                \n",
    "    for _, group in df_ecg.groupby('Participant'):\n",
    "        for i in range(0, len(group), samples_per_minute):\n",
    "            ecg_segment = group.iloc[i:i+samples_per_minute]\n",
    "            if len(ecg_segment) == samples_per_minute:\n",
    "                features = extract_pqrst_features(ecg_segment['ECG'].values, sample_rate)\n",
    "                features.update({\n",
    "                    'Participant': group['Participant'].iloc[0],\n",
    "                    'Sample': i,\n",
    "                    'Sampling_Rate': sample_rate,\n",
    "                    'Database': group['Database'].iloc[0],\n",
    "                    'Gender': group['Gender'].iloc[0],\n",
    "                    'Age': group['Age'].iloc[0]\n",
    "                })\n",
    "                all_features.append(features)\n",
    "\n",
    "    return pd.DataFrame(all_features)\n",
    "\n",
    "df_ecg = pd.read_csv(\"mit-bih_ECGs.csv\")\n",
    "\n",
    "# drop NaNs\n",
    "df_ecg = df_ecg.dropna()\n",
    "\n",
    "# Assume the sampling rate needs to be defined\n",
    "sample_rate = 360  # Define the correct sample rate for your data\n",
    "\n",
    "# Process and extract features from the ECG data\n",
    "# features_df = process_ecg_data(df_ecg, sample_rate)\n",
    "\n",
    "# Process and save features by participant in df_ecg, save each user's data in a separate CSV file\n",
    "participants = df_ecg['Participant'].unique()\n",
    "# Report how many participants are being processed and how many failed\n",
    "pcount = len(participants)\n",
    "print(f\"Processing data for {pcount} participants.\")\n",
    "failed = 0\n",
    "for participant in participants:\n",
    "    if participant in [\"mit-bih_16\", \"mit-bih_17\"]:\n",
    "        print(f\"Processing data for Participant: {participant}\")\n",
    "        participant_data = df_ecg[df_ecg['Participant'] == participant]\n",
    "        try:\n",
    "            features = process_ecg_data(participant_data, sample_rate)\n",
    "            # Save the extracted features to a new CSV file\n",
    "            features.to_csv(f\"mit-bih_features/mit-bih_features_{participant}.csv\", index=False)\n",
    "            print(f\"Extracted features saved to 'mit-bih_features/mit-bih_features_{participant}.csv'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing data for Participant: {participant}\")\n",
    "            print(e)\n",
    "            # raise e\n",
    "            failed += 1\n",
    "    print(f\"Processing completed. {failed} participants failed to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the files \"f\"mit-bih_features/smart_features_{participant}.csv\"\" to \"f\"mit-bih_features/mit-bih_features_{participant}.csv\"\"\n",
    "import os\n",
    "# give me the code\n",
    "directory = \"mit-bih_features/\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"smart_features_\"):\n",
    "        os.rename(directory + filename, directory + filename.replace(\"smart_features_\", \"mit-bih_features_\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
